import json
import os
import subprocess
import xmltodict

from django.utils import timezone
import docker
import sys

from background_task import background

from gvm.connections import TLSConnection
from gvm.errors import GvmError
from gvm.transforms import EtreeCheckCommandTransform
from gvm.protocols.gmp import Gmp

from .models import TaskPentest, ThreatPentest
from .toolsDjango import executeCommand
from background_task.models import Task, CompletedTask

from django.conf import settings

'''
def get_process_status(parameters):
    now = timezone.now()
    # pending tasks will have `run_at` column greater than current time.
    # Similar for running tasks, it shall be
    # greater than or equal to `locked_at` column.
    # Running tasks won't work with SQLite DB,
    # because of concurrency issues in SQLite.
    # If your task still not started running and waiting in the queue, then you  can find it in pending_tasks

    pending_tasks = Task.objects.filter(run_at__gt=now)

    # If your task is in running state, you can find it in running_tasks

    running_tasks = Task.objects.filter(locked_at__gte=now)

    # Completed tasks goes in `CompletedTask` model.
    # I have picked all, you can choose to filter based on what you want.
    # If your task completed you can find it in Completed task model.

    completed_tasks = CompletedTask.objects.all()

    # If you want the result in json format just add .values() at the end of the
    # ORM query like "completed_tasks = CompletedTask.objects.all().values()"
    print(completed_tasks, running_tasks, pending_tasks)
'''

client = docker.from_env()


def is_scheduled(task_name):
    task_fullname = 'PentestTB.tasks.' + task_name
    task = Task.objects.filter(task_name=task_fullname)
    if task:
        print("Task " + task_name + " is scheduled")
        return True
    else:
        print("Task " + task_name + " is not scheduled")
        return False


def exists(task_name):
    task_fullname = 'PentestTB.tasks.' + task_name
    task = Task.objects.filter(task_name=task_fullname)
    taskCompleted = CompletedTask.objects.filter(task_name=task_fullname)
    if task or taskCompleted:
        print("Task " + task_name + " exists")
        return True
    else:
        print("Task " + task_name + " does not exist")
        return False


def get_process_status(task_name):
    if exists(task_name):
        now = timezone.now()
        task_fullname = 'PentestTB.tasks.' + task_name
        task = Task.objects.filter(task_name=task_fullname)
        taskCompleted = CompletedTask.objects.filter(task_name=task_fullname)
        if task:
            print("Task " + task_name + " is pending/running")
            return "running"
        elif taskCompleted:
            print("Task " + task_name + " is completed")
            return "completed"
    else:
        return "not created"


def start_background_task(task_name, task_function, *args):
    print("in start " + task_name)
    if not is_scheduled(task_name):
        print("creating task " + task_name)
        task_function(*args)
        return True
    else:
        print("Task " + task_name + " already created")
        return False


@background(schedule=20)
def test():
    res, err = executeCommand('whoami')
    print(res, err)


@background
def restartNetworking():
    res, err = executeCommand('systemctl restart networking.service')
    print(res, err)


def getContainerStatus(container_name):
    if client.containers.list(all=True, filters={"name": container_name}):
        state = client.containers.get(container_name).attrs['State']
        if state['Running']:
            print(f"Status of {container_name}: {state['Status']}")
            healthContainer = state['Health']
            return healthContainer['Status']
        else:
            return "not_running"
    else:
        return "not_started"


###### Openvas functions ######

def startupOpenvas(restart=False):
    if not exists("startOpenvas"):
        startOpenvas()
    if restart and not is_scheduled("startOpenvas"):
        startOpenvas()


@background
def startOpenvas():
    print("creating openvas container...")
    docker_file_path = str(settings.STATIC_ROOT) + '/docker/openvas/'
    print(docker_file_path)
    image_name = "updated_immauss/openvas"
    container_name = "openvas"
    host_folder = str(settings.BASE_DIR) + '/data/openvasReports/'
    container_folder = '/openvas/reports/'

    if not client.images.list(name=image_name):
        client.images.build(path=docker_file_path, dockerfile='immauss-openvas', pull=True, tag=image_name)

    if client.containers.list(all=True, filters={"name": container_name}):
        container = client.containers.get(container_name)
        container.stop()
        container.remove()

    image = client.images.get(image_name)

    port = {'9392/tcp': 9392, '9390/tcp': 9390}
    volumes = {host_folder: {'bind': container_folder, 'mode': 'rw'}}

    client.containers.run(image, detach=True, name=container_name, ports=port, volumes=volumes)


@background
def startTaskOpenvas(taskPT_id, task_name, target_name, target_hosts):
    command = f"python3 /openvas/startTask.py {task_name} {target_name} {target_hosts}"
    container_name = "openvas"
    container = client.containers.get(container_name)

    # docker_command = f"docker exec -it {container_name} bash -c {command}"
    # print(docker_command)

    exit_code, output = container.exec_run(command.split())
    output = output.decode('utf-8')

    string = ""
    for letter in output:
        string += letter

    line = string.split(":")
    report_id = line[1]
    report_id = report_id.replace(" ", "")
    report_id = report_id.replace("\n", "")

    print(f'Report_id: {report_id}')

    with open(f"{settings.BASE_DIR}/data/openvasReports/{report_id}/{report_id}.json", "r") as f:
        data = json.load(f)
        taskPT = TaskPentest.objects.get(id=taskPT_id)
        taskPT.dataTools["openvas"] = data
        taskPT.save()


def getOpenvasTaskStatus(taskPT_id):
    taskPT = TaskPentest.objects.get(id=taskPT_id)
    data = taskPT.dataTools["openvas"]
    print(data["task_id"])
    task_id = data["task_id"]

    username = 'admin'
    password = 'cyber2023'
    hostname = '0.0.0.0'

    try:
        connection = TLSConnection(hostname=hostname)
        transform = EtreeCheckCommandTransform()

        with Gmp(connection, transform=transform) as gmp:
            gmp.authenticate(username, password)
            task = gmp.get_task(task_id).xpath("task")
            task_status = task[0].xpath("status/text()")[0]
            return task_status

    except GvmError as e:
        print('An error occurred: {}'.format(e), file=sys.stderr)
        return "task not found on openvas"


@background
def parseXMLOpenvasToMSF(taskPT_id):
    taskPT = TaskPentest.objects.get(id=taskPT_id)
    data = taskPT.dataTools["openvas"]
    report_id = data["report_id"]

    with open(f'{settings.BASE_DIR}/data/openvasReports/{report_id}.xml', 'r') as f:
        json_data = xmltodict.parse(f.read())

        results = json_data["report"]["report"]["results"]["result"]
        severity_threshold = 5.0

        json_output = {}
        index = 0
        for i in range(len(results)):
            result = results[i]
            if float(result["severity"]) >= severity_threshold:
                name = result["name"]
                host = result["host"]["#text"]
                port = result["port"]
                cve = result["nvt"]["cve"]

                ThreatPentest.objects.create(taskPentest=taskPT, name=name, host=host, port=port, cve=cve)

                if not "NOCVE" == cve:
                    tmp = {
                        "name": name,
                        "host": host,
                        "port": port,
                        "cve": result["nvt"]["cve"]
                    }
                    json_output[index] = tmp
                    index += 1

        print(json.dumps(json_output, indent=4))


        with open(f'{settings.BASE_DIR}/data/openvasReports/MSF_{report_id}.json', 'w') as json_file:
            json.dump(json_output, json_file, indent=4)

        container_name = "msf"
        print(f"creating {container_name} container...")
        docker_file_path = str(settings.STATIC_ROOT) + '/docker/metasploit/'
        print(docker_file_path)
        image_name = "msfconsole"
        host_folder = str(settings.BASE_DIR) + '/data/msfOutputs/'
        container_folder = '/rcFiles/tmp/'

        if not client.images.list(name=image_name):
            client.images.build(path=docker_file_path, dockerfile='msfDF', pull=True, tag=image_name)

        if client.containers.list(all=True, filters={"name": container_name}):
            container = client.containers.get(container_name)
            container.stop()
            container.remove()

        image = client.images.get(image_name)

        volumes = {host_folder: {'bind': container_folder, 'mode': 'rw'}}

        container = client.containers.run(image, detach=True, name=container_name, volumes=volumes)

        for i in range(len(json_output)):
            print(f"running exploit for {json_output[i]['cve']}")

            cve = json_output[i]["cve"].split(",")[0]
            cve_year = cve.split("-")[0]
            print(cve_year)

            host = json_output[i]["host"]
            port = json_output[i]["port"]

        container.exec_run(f"python3 /rcFiles/runExploit.py {cve_year} {host} {port}".split())


def getOutputMSFconsole():

    if not os.path.exists(f"{settings.BASE_DIR}/data/msfOutputs/exploits.txt"):
        return "no output"
    else:
        with open(f'{settings.BASE_DIR}/data/msfOutputs/exploit.txt', 'r') as f:
            return f.read()

